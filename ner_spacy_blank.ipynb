{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and load the spacy model\n",
    "import spacy\n",
    "nlp=spacy.load(\"en_core_web_sm\") \n",
    "\n",
    "# Getting the ner component\n",
    "ner=nlp.get_pipe('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New label to add\n",
    "LABEL = \"FOOD\"\n",
    "\n",
    "# Training examples in the required format\n",
    "TRAIN_DATA =[ (\"Pizza is a common fast food.\", {\"entities\": [(0, 5, \"FOOD\")]}),\n",
    "              (\"Pasta is an italian recipe\", {\"entities\": [(0, 5, \"FOOD\")]}),\n",
    "              (\"China's noodles are very famous\", {\"entities\": [(8,15, \"FOOD\")]}),\n",
    "              (\"Shrimps are famous in China too\", {\"entities\": [(0,7, \"FOOD\")]}),\n",
    "              (\"Lasagna is another classic of Italy\", {\"entities\": [(0,7, \"FOOD\")]}),\n",
    "              (\"Sushi and kougefdsjofs is extemely famous and expensive Japanese dish\", {\"entities\": [(0,5, \"FOOD\"),(10,22, \"FOOD\")]}),\n",
    "              (\"Unagi is a famous seafood of Japan\", {\"entities\": [(0,5, \"FOOD\")]}),\n",
    "              (\"Tempura , Soba are other famous dishes of Japan\", {\"entities\": [(0,7, \"FOOD\")]}),\n",
    "              (\"Udon is a healthy type of noodles\", {\"entities\": [(0,4, \"ORG\")]}),\n",
    "              (\"Chocolate souffl√© is extremely famous french cuisine\", {\"entities\": [(0,17, \"FOOD\")]}),\n",
    "              (\"Flamiche is french pastry\", {\"entities\": [(0,8, \"FOOD\")]}),\n",
    "              (\"Burgers are the most commonly consumed fastfood\", {\"entities\": [(0,7, \"FOOD\")]}),\n",
    "              (\"Frenchfries are considered too oily\", {\"entities\": [(0,11, \"FOOD\")]})\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the new label to ner\n",
    "ner.add_label(LABEL)\n",
    "\n",
    "# Resume training\n",
    "optimizer = nlp.resume_training()\n",
    "move_names = list(ner.move_names)\n",
    "\n",
    "# List of pipes you want to train\n",
    "pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "\n",
    "# List of pipes which should remain unaffected in training\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 3.650657084887754e-07}\n",
      "Losses {'ner': 3.6507662455295716e-07}\n",
      "Losses {'ner': 3.6644789678293706e-07}\n",
      "Losses {'ner': 1.2137943594505864}\n",
      "Losses {'ner': 1.2137943637667201}\n",
      "Losses {'ner': 1.2137943829998579}\n",
      "Losses {'ner': 3.2137931190812594}\n",
      "Losses {'ner': 3.2137931190858313}\n",
      "Losses {'ner': 3.2137931190877684}\n",
      "Losses {'ner': 3.28247000830861}\n",
      "Losses {'ner': 3.282470012618467}\n",
      "Losses {'ner': 3.282470150611731}\n",
      "Losses {'ner': 3.282470150629006}\n",
      "Losses {'ner': 3.0404648412112055e-10}\n",
      "Losses {'ner': 3.925307365126699e-09}\n",
      "Losses {'ner': 4.084106691064048e-09}\n",
      "Losses {'ner': 2.1067670620316077e-08}\n",
      "Losses {'ner': 2.5757029786412258e-08}\n",
      "Losses {'ner': 2.701678506644333e-08}\n",
      "Losses {'ner': 2.702041593003945e-08}\n",
      "Losses {'ner': 1.5328647664980477}\n",
      "Losses {'ner': 1.5332842456387767}\n",
      "Losses {'ner': 1.53328428256892}\n",
      "Losses {'ner': 1.5333230026367932}\n",
      "Losses {'ner': 1.5333230026917246}\n",
      "Losses {'ner': 1.5333230028126157}\n",
      "Losses {'ner': 2.345343845283784e-07}\n",
      "Losses {'ner': 2.3463870999098542e-07}\n",
      "Losses {'ner': 2.9480206133149564e-07}\n",
      "Losses {'ner': 9.51793417714066e-06}\n",
      "Losses {'ner': 0.011204253183186186}\n",
      "Losses {'ner': 0.011204308895499246}\n",
      "Losses {'ner': 0.011204332100762944}\n",
      "Losses {'ner': 0.012205267914126088}\n",
      "Losses {'ner': 0.012205267932577382}\n",
      "Losses {'ner': 0.012510353622753398}\n",
      "Losses {'ner': 0.016617768959785072}\n",
      "Losses {'ner': 0.01661842583947917}\n",
      "Losses {'ner': 0.016653750048457622}\n",
      "Losses {'ner': 1.7835942248618496e-05}\n",
      "Losses {'ner': 1.7835968578641277e-05}\n",
      "Losses {'ner': 0.7648539202912682}\n",
      "Losses {'ner': 0.764853928720323}\n",
      "Losses {'ner': 0.7648539327649617}\n",
      "Losses {'ner': 0.7648539634853332}\n",
      "Losses {'ner': 0.7648539637483518}\n",
      "Losses {'ner': 0.7648539858951141}\n",
      "Losses {'ner': 0.7648540784719068}\n",
      "Losses {'ner': 0.7648541651252411}\n",
      "Losses {'ner': 0.7648541651253505}\n",
      "Losses {'ner': 0.7648541656906361}\n",
      "Losses {'ner': 0.7648542190936657}\n",
      "Losses {'ner': 2.8478136736023883e-13}\n",
      "Losses {'ner': 2.221224176736676e-06}\n",
      "Losses {'ner': 2.221249069011666e-06}\n",
      "Losses {'ner': 2.2212494769925167e-06}\n",
      "Losses {'ner': 2.2450568708864928e-06}\n",
      "Losses {'ner': 8.771103916717102e-06}\n",
      "Losses {'ner': 8.771131932549298e-06}\n",
      "Losses {'ner': 8.825248941843274e-06}\n",
      "Losses {'ner': 1.2660981093589876e-05}\n",
      "Losses {'ner': 1.2660981547001217e-05}\n",
      "Losses {'ner': 1.2660981791419436e-05}\n",
      "Losses {'ner': 1.2660984096292661e-05}\n",
      "Losses {'ner': 0.004687933837281245}\n",
      "Losses {'ner': 0.0015730051679218003}\n",
      "Losses {'ner': 0.001573007874213915}\n",
      "Losses {'ner': 0.0015730444387023377}\n",
      "Losses {'ner': 0.0015730444392495799}\n",
      "Losses {'ner': 0.0015730447409489868}\n",
      "Losses {'ner': 0.10684069641054343}\n",
      "Losses {'ner': 0.10752872090134326}\n",
      "Losses {'ner': 0.10752872098760308}\n",
      "Losses {'ner': 0.10752872099045102}\n",
      "Losses {'ner': 0.10752872333090788}\n",
      "Losses {'ner': 0.107528755590364}\n",
      "Losses {'ner': 0.10752963199905459}\n",
      "Losses {'ner': 0.10752963436931473}\n",
      "Losses {'ner': 2.7830685234330686e-05}\n",
      "Losses {'ner': 3.001149088275481e-05}\n",
      "Losses {'ner': 3.001177404614454e-05}\n",
      "Losses {'ner': 3.0386333064245885e-05}\n",
      "Losses {'ner': 3.038639720353251e-05}\n",
      "Losses {'ner': 3.0406572832835856e-05}\n",
      "Losses {'ner': 5.1882740032578344e-05}\n",
      "Losses {'ner': 5.200908972246233e-05}\n",
      "Losses {'ner': 5.2009170126765455e-05}\n",
      "Losses {'ner': 5.2180959792064834e-05}\n",
      "Losses {'ner': 5.218096005291585e-05}\n",
      "Losses {'ner': 5.2181171912427396e-05}\n",
      "Losses {'ner': 5.218903685162835e-05}\n",
      "Losses {'ner': 1.6542841405861712e-09}\n",
      "Losses {'ner': 7.736529819221393e-06}\n",
      "Losses {'ner': 7.764377357869879e-06}\n",
      "Losses {'ner': 7.764377449833916e-06}\n",
      "Losses {'ner': 7.76441787754836e-06}\n",
      "Losses {'ner': 7.764418339397082e-06}\n",
      "Losses {'ner': 7.764834308448884e-06}\n",
      "Losses {'ner': 7.765212882524125e-06}\n",
      "Losses {'ner': 7.76526988974737e-06}\n",
      "Losses {'ner': 7.765639511025727e-06}\n",
      "Losses {'ner': 9.096840319656892e-06}\n",
      "Losses {'ner': 0.004650455582254836}\n",
      "Losses {'ner': 0.004659335525676251}\n",
      "Losses {'ner': 2.722061577980339e-09}\n",
      "Losses {'ner': 3.0332992315637564e-09}\n",
      "Losses {'ner': 8.515895575301536e-08}\n",
      "Losses {'ner': 8.515922724096873e-08}\n",
      "Losses {'ner': 8.515933366516063e-08}\n",
      "Losses {'ner': 8.515991134066818e-08}\n",
      "Losses {'ner': 4.540982733393434e-06}\n",
      "Losses {'ner': 4.5409914022683334e-06}\n",
      "Losses {'ner': 4.5413101901461834e-06}\n",
      "Losses {'ner': 4.541310247543337e-06}\n",
      "Losses {'ner': 4.554142082506164e-06}\n",
      "Losses {'ner': 5.443164933088592e-06}\n",
      "Losses {'ner': 5.444672373092911e-06}\n",
      "Losses {'ner': 1.9282212805683997e-09}\n",
      "Losses {'ner': 2.1411759427294022e-07}\n",
      "Losses {'ner': 0.0004236585453228611}\n",
      "Losses {'ner': 0.0004236805013593416}\n",
      "Losses {'ner': 0.0004236805019257289}\n",
      "Losses {'ner': 0.00042368053487448076}\n",
      "Losses {'ner': 0.00042463081359271463}\n",
      "Losses {'ner': 0.00042463081490545047}\n",
      "Losses {'ner': 0.00042490237331308444}\n",
      "Losses {'ner': 0.00042490237331813796}\n",
      "Losses {'ner': 0.0004249023854109015}\n",
      "Losses {'ner': 0.00042490238596979124}\n",
      "Losses {'ner': 0.00043720727456876345}\n",
      "Losses {'ner': 1.8868728198648497e-09}\n",
      "Losses {'ner': 1.891315375685725e-09}\n",
      "Losses {'ner': 1.943010155175753e-09}\n",
      "Losses {'ner': 1.943017930940015e-09}\n",
      "Losses {'ner': 2.584088500308492e-09}\n",
      "Losses {'ner': 3.2989732167077874e-09}\n",
      "Losses {'ner': 3.3201762799147313e-09}\n",
      "Losses {'ner': 3.553202143454822e-06}\n",
      "Losses {'ner': 5.128316973369095e-05}\n",
      "Losses {'ner': 5.128317125983827e-05}\n",
      "Losses {'ner': 5.138382355098724e-05}\n",
      "Losses {'ner': 5.1383909211735596e-05}\n",
      "Losses {'ner': 5.13896202576321e-05}\n",
      "Losses {'ner': 5.2012302175527845e-09}\n",
      "Losses {'ner': 5.2020724317912574e-09}\n",
      "Losses {'ner': 5.202245142221499e-09}\n",
      "Losses {'ner': 0.05640356019485545}\n",
      "Losses {'ner': 0.05640356019485737}\n",
      "Losses {'ner': 0.056403560194886376}\n",
      "Losses {'ner': 0.0691983644945441}\n",
      "Losses {'ner': 0.06919836455706405}\n",
      "Losses {'ner': 0.06919836459341552}\n",
      "Losses {'ner': 0.06919836459341615}\n",
      "Losses {'ner': 0.06919838461482081}\n",
      "Losses {'ner': 0.06919838461482085}\n",
      "Losses {'ner': 0.06919921002875298}\n",
      "Losses {'ner': 1.6882422635380072e-13}\n",
      "Losses {'ner': 1.799358195711431e-13}\n",
      "Losses {'ner': 1.4543480746275275e-09}\n",
      "Losses {'ner': 1.4911297008190212e-09}\n",
      "Losses {'ner': 1.5056423572913015e-09}\n",
      "Losses {'ner': 1.5088496838785285e-09}\n",
      "Losses {'ner': 1.4372736922992673e-08}\n",
      "Losses {'ner': 1.4372788551573265e-08}\n",
      "Losses {'ner': 2.771354662674576e-06}\n",
      "Losses {'ner': 5.361946118555619e-05}\n",
      "Losses {'ner': 5.362129046898444e-05}\n",
      "Losses {'ner': 5.3621323090751676e-05}\n",
      "Losses {'ner': 0.0006895436641535013}\n",
      "Losses {'ner': 2.2168322697275443e-07}\n",
      "Losses {'ner': 2.2384338950488477e-07}\n",
      "Losses {'ner': 2.2394950437966144e-07}\n",
      "Losses {'ner': 0.00011400970911984455}\n",
      "Losses {'ner': 0.00011400984941575285}\n",
      "Losses {'ner': 0.0001142166964108282}\n",
      "Losses {'ner': 0.00011421669641423615}\n",
      "Losses {'ner': 0.00011421690542520812}\n",
      "Losses {'ner': 0.00011422803647765303}\n",
      "Losses {'ner': 0.00011422955216855966}\n",
      "Losses {'ner': 0.00011474177285017426}\n",
      "Losses {'ner': 0.00011474179722336048}\n",
      "Losses {'ner': 0.0001147420773626171}\n",
      "Losses {'ner': 2.6979602656418387e-11}\n",
      "Losses {'ner': 2.6992617297646478e-11}\n",
      "Losses {'ner': 1.1575332430640985e-08}\n",
      "Losses {'ner': 1.1587700063260756e-08}\n",
      "Losses {'ner': 0.37181932892855113}\n",
      "Losses {'ner': 0.3718193295330424}\n",
      "Losses {'ner': 0.37181946662034565}\n",
      "Losses {'ner': 0.371819888395245}\n",
      "Losses {'ner': 0.3718198937166935}\n",
      "Losses {'ner': 0.9219437890543098}\n",
      "Losses {'ner': 0.9219438450434609}\n",
      "Losses {'ner': 0.9219438501784645}\n",
      "Losses {'ner': 0.9219438514418385}\n",
      "Losses {'ner': 4.237552970606085e-10}\n",
      "Losses {'ner': 4.237553840405537e-10}\n",
      "Losses {'ner': 4.237586295801063e-10}\n",
      "Losses {'ner': 4.6498699474473854e-10}\n",
      "Losses {'ner': 5.129383971336603e-10}\n",
      "Losses {'ner': 8.123397202286002e-09}\n",
      "Losses {'ner': 8.124623685057122e-09}\n",
      "Losses {'ner': 8.362442988795056e-09}\n",
      "Losses {'ner': 8.362452494617801e-09}\n",
      "Losses {'ner': 8.93820355617799e-09}\n",
      "Losses {'ner': 1.1030200733498935e-08}\n",
      "Losses {'ner': 1.0350847583930676e-05}\n",
      "Losses {'ner': 1.0350847583931001e-05}\n",
      "Losses {'ner': 5.847306752643191e-16}\n",
      "Losses {'ner': 1.1549572001479982e-15}\n",
      "Losses {'ner': 1.595857962717816e-13}\n",
      "Losses {'ner': 1.348046161277306e-10}\n",
      "Losses {'ner': 1.5582876896297578e-10}\n",
      "Losses {'ner': 1.0078535848041467e-08}\n",
      "Losses {'ner': 1.0087984658286808e-08}\n",
      "Losses {'ner': 1.0192776135953852e-08}\n",
      "Losses {'ner': 0.003032737380144652}\n",
      "Losses {'ner': 0.003212923400189632}\n",
      "Losses {'ner': 0.003212923400191109}\n",
      "Losses {'ner': 0.003212923597779225}\n",
      "Losses {'ner': 0.003212923598002221}\n",
      "Losses {'ner': 5.84528458006731e-07}\n",
      "Losses {'ner': 5.847707475512103e-07}\n",
      "Losses {'ner': 2.3766509527642707}\n",
      "Losses {'ner': 2.376650952764809}\n",
      "Losses {'ner': 2.376650953161045}\n",
      "Losses {'ner': 2.3766509531610467}\n",
      "Losses {'ner': 2.3766509531613926}\n",
      "Losses {'ner': 2.3766509667998696}\n",
      "Losses {'ner': 2.3770546241185624}\n",
      "Losses {'ner': 2.377059371848975}\n",
      "Losses {'ner': 2.37705937185547}\n",
      "Losses {'ner': 2.37705937185547}\n",
      "Losses {'ner': 2.3770593718558284}\n",
      "Losses {'ner': 1.928209093457105e-11}\n",
      "Losses {'ner': 2.687698803339835e-11}\n",
      "Losses {'ner': 2.691607719273393e-11}\n",
      "Losses {'ner': 2.270957713045872e-09}\n",
      "Losses {'ner': 2.27095796012153e-09}\n",
      "Losses {'ner': 2.271041653082575e-09}\n",
      "Losses {'ner': 2.3151193543236817e-09}\n",
      "Losses {'ner': 2.3151203946220123e-09}\n",
      "Losses {'ner': 1.3915512584953154}\n",
      "Losses {'ner': 1.3915512657808093}\n",
      "Losses {'ner': 3.3705726969498846}\n",
      "Losses {'ner': 3.370572696950134}\n",
      "Losses {'ner': 3.370572696950177}\n",
      "Losses {'ner': 1.3735002180227033e-12}\n",
      "Losses {'ner': 2.5839697913181448e-12}\n",
      "Losses {'ner': 1.1734444667947203e-10}\n",
      "Losses {'ner': 0.0016861214702193414}\n",
      "Losses {'ner': 0.0016861271883529387}\n",
      "Losses {'ner': 0.0016861501080579452}\n",
      "Losses {'ner': 0.0016861501087497973}\n",
      "Losses {'ner': 0.0016861501087548053}\n",
      "Losses {'ner': 0.0016861533202267734}\n",
      "Losses {'ner': 0.0016861535875012767}\n",
      "Losses {'ner': 0.0016861912288165899}\n",
      "Losses {'ner': 0.0016861913103526356}\n",
      "Losses {'ner': 0.001686191330455676}\n",
      "Losses {'ner': 3.592127258902707e-10}\n",
      "Losses {'ner': 3.6872998123144347e-10}\n",
      "Losses {'ner': 6.351290674385001e-09}\n",
      "Losses {'ner': 9.876708373039399e-09}\n",
      "Losses {'ner': 9.921028207672101e-09}\n",
      "Losses {'ner': 1.0700562855507932e-08}\n",
      "Losses {'ner': 1.4466382385729073e-08}\n",
      "Losses {'ner': 1.4591954074054133e-08}\n",
      "Losses {'ner': 1.4591956643571418e-08}\n",
      "Losses {'ner': 1.4667842630789069e-08}\n",
      "Losses {'ner': 1.0353860005090443e-05}\n",
      "Losses {'ner': 2.1216872884943377e-05}\n",
      "Losses {'ner': 2.121687457471338e-05}\n",
      "Losses {'ner': 2.555029864411891e-11}\n",
      "Losses {'ner': 3.24584418220281e-09}\n",
      "Losses {'ner': 3.247774275018573e-09}\n",
      "Losses {'ner': 3.2478102219816596e-09}\n",
      "Losses {'ner': 3.249425693327861e-09}\n",
      "Losses {'ner': 3.2502302028419998e-09}\n",
      "Losses {'ner': 3.2538404274083853e-09}\n",
      "Losses {'ner': 2.0055194628992296e-07}\n",
      "Losses {'ner': 2.0055367622373057e-07}\n",
      "Losses {'ner': 2.0055371007901654e-07}\n",
      "Losses {'ner': 5.546750192009787e-06}\n",
      "Losses {'ner': 5.547051797510649e-06}\n",
      "Losses {'ner': 5.547067920825688e-06}\n",
      "Losses {'ner': 1.8063601572605583e-11}\n",
      "Losses {'ner': 9.426413099163798e-06}\n",
      "Losses {'ner': 0.005895863298528701}\n",
      "Losses {'ner': 0.005895866307021457}\n",
      "Losses {'ner': 0.005895866398920338}\n",
      "Losses {'ner': 0.005895866407438407}\n",
      "Losses {'ner': 0.005895870538348647}\n",
      "Losses {'ner': 0.005895870902642767}\n",
      "Losses {'ner': 0.005895874812113318}\n",
      "Losses {'ner': 0.0058958748144154844}\n",
      "Losses {'ner': 0.005895875571829096}\n",
      "Losses {'ner': 0.005895875654986444}\n",
      "Losses {'ner': 0.005895875821975876}\n",
      "Losses {'ner': 2.9576814420217133e-16}\n",
      "Losses {'ner': 4.020854955573281e-12}\n",
      "Losses {'ner': 3.597360017328312e-09}\n",
      "Losses {'ner': 2.25941493271884e-08}\n",
      "Losses {'ner': 2.2603662741307516e-08}\n",
      "Losses {'ner': 2.261524825766424e-08}\n",
      "Losses {'ner': 2.261527233479302e-08}\n",
      "Losses {'ner': 2.4575028873384548e-08}\n",
      "Losses {'ner': 2.4575638822964233e-08}\n",
      "Losses {'ner': 2.8300314081213826e-08}\n",
      "Losses {'ner': 2.8300487701706203e-08}\n",
      "Losses {'ner': 2.83068043884419e-08}\n",
      "Losses {'ner': 2.8308735897461048e-08}\n",
      "Losses {'ner': 1.048144796087945e-08}\n",
      "Losses {'ner': 1.5554703240039406e-07}\n",
      "Losses {'ner': 1.555577691611328e-07}\n",
      "Losses {'ner': 1.55568393517509e-07}\n",
      "Losses {'ner': 1.5733145965336793e-07}\n",
      "Losses {'ner': 1.837781918531102e-07}\n",
      "Losses {'ner': 1.8378156887269084e-07}\n",
      "Losses {'ner': 1.8378156901082725e-07}\n",
      "Losses {'ner': 1.8379027986763463e-07}\n",
      "Losses {'ner': 1.8393884216064684e-07}\n",
      "Losses {'ner': 1.8393889486722047e-07}\n",
      "Losses {'ner': 1.8399692827077675e-07}\n",
      "Losses {'ner': 1.8399701759837394e-07}\n",
      "Losses {'ner': 2.2797067497442373e-08}\n",
      "Losses {'ner': 2.279707055498667e-08}\n",
      "Losses {'ner': 1.985101964364892e-06}\n",
      "Losses {'ner': 1.985105280980596e-06}\n",
      "Losses {'ner': 1.993789444400781e-06}\n",
      "Losses {'ner': 1.9954893172054257e-06}\n",
      "Losses {'ner': 1.995489334187043e-06}\n",
      "Losses {'ner': 1.9954913024049163e-06}\n",
      "Losses {'ner': 1.995491784530044e-06}\n",
      "Losses {'ner': 1.9956986365111276e-06}\n",
      "Losses {'ner': 1.9957508577586603e-06}\n",
      "Losses {'ner': 1.995750865704804e-06}\n",
      "Losses {'ner': 1.995752218424952e-06}\n",
      "Losses {'ner': 5.007995499488205e-15}\n",
      "Losses {'ner': 1.2906321904989495e-08}\n",
      "Losses {'ner': 1.2906465345221078e-08}\n",
      "Losses {'ner': 1.290649839125133e-08}\n",
      "Losses {'ner': 1.2906502393870365e-08}\n",
      "Losses {'ner': 1.2906631120010984e-08}\n",
      "Losses {'ner': 1.2907114601594527e-08}\n",
      "Losses {'ner': 1.536077584997273e-08}\n",
      "Losses {'ner': 1.8402068473563862e-08}\n",
      "Losses {'ner': 1.840207364810558e-08}\n",
      "Losses {'ner': 1.866596286123242e-08}\n",
      "Losses {'ner': 1.8667329444866607e-08}\n",
      "Losses {'ner': 1.8720206561823376e-08}\n",
      "Losses {'ner': 7.114009455684826e-12}\n",
      "Losses {'ner': 3.6070299617957466e-09}\n",
      "Losses {'ner': 3.6072062806186893e-09}\n",
      "Losses {'ner': 3.6072065408773424e-09}\n",
      "Losses {'ner': 1.3280102059440736e-06}\n",
      "Losses {'ner': 1.3280106680094014e-06}\n",
      "Losses {'ner': 1.3280127431896413e-06}\n",
      "Losses {'ner': 1.3286471542723173e-06}\n",
      "Losses {'ner': 7.648354472529275e-06}\n",
      "Losses {'ner': 7.648354561136065e-06}\n",
      "Losses {'ner': 7.648354568113236e-06}\n",
      "Losses {'ner': 7.649535082674531e-06}\n",
      "Losses {'ner': 7.649535202031914e-06}\n",
      "Losses {'ner': 6.123718590010781e-13}\n",
      "Losses {'ner': 6.125793034109681e-13}\n",
      "Losses {'ner': 7.927294407363416e-12}\n",
      "Losses {'ner': 3.2752349652216125e-10}\n",
      "Losses {'ner': 3.2105952099034742e-09}\n",
      "Losses {'ner': 3.2302708602338803e-09}\n",
      "Losses {'ner': 4.159695037094198e-09}\n",
      "Losses {'ner': 4.159696151834477e-09}\n",
      "Losses {'ner': 4.161295911880326e-09}\n",
      "Losses {'ner': 6.330793615784781e-09}\n",
      "Losses {'ner': 6.3312551374578475e-09}\n",
      "Losses {'ner': 2.329659686599008e-08}\n",
      "Losses {'ner': 2.3325428358083833e-08}\n",
      "Losses {'ner': 4.782749454220262e-10}\n",
      "Losses {'ner': 4.6838076376673934e-07}\n",
      "Losses {'ner': 4.6850370952162947e-07}\n",
      "Losses {'ner': 4.726136194320071e-07}\n",
      "Losses {'ner': 4.7261402694231085e-07}\n",
      "Losses {'ner': 4.726143181272174e-07}\n",
      "Losses {'ner': 4.7261431843714146e-07}\n",
      "Losses {'ner': 4.7277495131495695e-07}\n",
      "Losses {'ner': 4.727749584593783e-07}\n",
      "Losses {'ner': 5.113309656427261e-07}\n",
      "Losses {'ner': 5.114029361546517e-07}\n",
      "Losses {'ner': 5.114131472916076e-07}\n",
      "Losses {'ner': 5.295367161829175e-07}\n"
     ]
    }
   ],
   "source": [
    "# Importing requirements\n",
    "from spacy.util import minibatch, compounding\n",
    "from spacy.training.example import Example\n",
    "import random\n",
    "\n",
    "# Begin training by disabling other pipeline components\n",
    "with nlp.disable_pipes(*other_pipes) :\n",
    "\n",
    "  sizes = compounding(1.0, 4.0, 1.001)\n",
    "  # Training for 30 iterations     \n",
    "  for itn in range(30):\n",
    "    # shuffle examples before training\n",
    "    random.shuffle(TRAIN_DATA)\n",
    "    # batch up the examples using spaCy's minibatch\n",
    "    batches = minibatch(TRAIN_DATA, size=sizes)\n",
    "    # ictionary to store losses\n",
    "    losses = {}\n",
    "    for batch in batches:\n",
    "        for text, annotations in batch:\n",
    "            # create Example\n",
    "            doc = nlp.make_doc(text)\n",
    "            example = Example.from_dict(doc, annotations)\n",
    "            # Update the model\n",
    "            nlp.update([example], losses=losses, drop=0.5)\n",
    "            print(\"Losses\", losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities [('kougefdsjofs', 'FOOD')]\n"
     ]
    }
   ],
   "source": [
    "# Testing the NER\n",
    "\n",
    "test_text = \"I ate kougefdsjof and kougefdsjofs and kougefds yesterday. they are a common fast food \"\n",
    "doc = nlp(test_text)\n",
    "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to \\content\n",
      "Loading from \\content\n",
      "FOOD Dosa\n"
     ]
    }
   ],
   "source": [
    "# Output directory\n",
    "from pathlib import Path\n",
    "output_dir=Path('/content/')\n",
    "\n",
    "# Saving the model to the output directory\n",
    "if not output_dir.exists():\n",
    "  output_dir.mkdir()\n",
    "nlp.meta['name'] = 'my_ner'  # rename model\n",
    "nlp.to_disk(output_dir)\n",
    "print(\"Saved model to\", output_dir)\n",
    "\n",
    "# Loading the model from the directory\n",
    "print(\"Loading from\", output_dir)\n",
    "nlp2 = spacy.load(output_dir)\n",
    "assert nlp2.get_pipe(\"ner\").move_names == move_names\n",
    "doc2 = nlp2(' Dosa is an extremely famous south Indian dish')\n",
    "for ent in doc2.ents:\n",
    "  print(ent.label_, ent.text)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7c6135ec8961d9a7a91e6bf2a9a572c024e771794329222cfa63ad5fc4229083"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
